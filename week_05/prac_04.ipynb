{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('vertebrate.csv', header='infer')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'] = data['Class'].replace(['fishes', 'birds', 'amphibians', 'reptiles'], 'non-mammals')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y = data['Class']\n",
    "X = data.drop(['Name', 'Class'], axis=1)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "tree.plot_tree(clf, feature_names=['Warm-blooded', 'Gives Birth', \n",
    "'Aquatic Creature', 'Aerial Creature', 'Has Legs', 'Hibernates'], class_names=['mammals', 'non-mammals'], filled=True, rounded=True, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "tree_rules = export_text(clf, feature_names=['Warm-blooded', 'Gives Birth', \n",
    "'Aquatic Creature', 'Aerial Creature', 'Has Legs', 'Hibernates'])\n",
    "\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, test_x, y_train, test_lab = train_test_split(X, Y, test_size = 0.4, random_state = 42)\n",
    "test_pred_decision_tree = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant packages\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(test_lab, test_pred_decision_tree)\n",
    "\n",
    "# Turn this into a dataframe\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "# Plot the result\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "\n",
    "# Set axis titles\n",
    "ax.set_title('Confusion Matrix - Decision Tree')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize=15)\n",
    "ax.set_xticklabels(['mammals', 'non-mammals'])\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "ax.set_yticklabels(['mammals', 'non-mammals'], rotation = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_lab, test_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "N = 1500\n",
    "\n",
    "mean1 = [6, 14]\n",
    "mean2 = [10, 6]\n",
    "mean3 = [14, 14]\n",
    "cov = [[3.5, 0], [0, 3.5]]  # diagonal covariance\n",
    "\n",
    "np.random.seed(50)\n",
    "X = np.random.multivariate_normal(mean1, cov, int(N/6))\n",
    "X = np.concatenate((X, np.random.multivariate_normal(mean2, cov, int(N/6))))\n",
    "X = np.concatenate((X, np.random.multivariate_normal(mean3, cov, int(N/6))))\n",
    "X = np.concatenate((X, 20*np.random.rand(int(N/2),2)))\n",
    "Y = np.concatenate((np.ones(int(N/2)), np.zeros(int(N/2))))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(X[:int(N/2), 0], X[:int(N/2), 1], 'r+', X[int(N/2):, 0], X[int(N/2):, 1], 'k.', ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Training and Test set creation\n",
    "#########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.8, random_state=1)\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#########################################\n",
    "# Model fitting and evaluation\n",
    "#########################################\n",
    "\n",
    "maxdepths = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "trainAcc = np.zeros(len(maxdepths))\n",
    "testAcc = np.zeros(len(maxdepths))\n",
    "\n",
    "index = 0\n",
    "for depth in maxdepths:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(maxdepths,trainAcc, 'ro-', maxdepths, testAcc, 'bv--')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, test_x, y_train, test_lab = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_lab, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", metrics.precision_score(test_lab, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", metrics.recall_score(test_lab, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c695747066738daaf25c6df83a29a1527e2d92ef2e8550e75d41ccc17028d92"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('env-03': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
