{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('BlackFriday.csv', header='infer')\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Age', 'Marital_Status', 'Purchase', 'Gender']]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Purchase'] = pd.qcut(data['Purchase'], 3, labels=[0, 1, 2])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Marital_Status'] = pd.Categorical(data['Marital_Status'])\n",
    "data['Gender'] = pd.Categorical(data['Gender'])\n",
    "\n",
    "print(data)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['Age'])\n",
    "data = pd.concat((df, data), axis=1)\n",
    "data = data.drop(['Age'], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = data['Gender']\n",
    "X = data.drop(['Gender'], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(x_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(clf.score(x_test, y_test)))\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "tree.plot_tree(clf, feature_names=['0-17', '18-25', '26-35', '36-45', '46-50', '51-55', '55+', 'Marital_Status', 'Purchase', 'Gender'], class_names=['M', 'F'], filled=True, rounded=True, fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "test_pred_decision_tree = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, test_pred_decision_tree)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(matrix_df, annot=True, fmt='g', ax=ax, cmap='magma')\n",
    "\n",
    "ax.set_title('Confusion Matrix - Decision Tree')\n",
    "ax.set_xlabel('Predicted label', fontsize=15)\n",
    "ax.set_xticklabels(['M', 'F'])\n",
    "ax.set_ylabel('True Label', fontsize=15)\n",
    "ax.set_yticklabels(['M', 'F'], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracty of K-NN classifier on training set: {:.2f}'.format(knn.score(x_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'.format(knn.score(x_test, y_test)))\n",
    "\n",
    "test_pred_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, test_pred_knn)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(matrix_df, annot=True, fmt='g', ax=ax, cmap='magma')\n",
    "\n",
    "ax.set_title('Confusion Matrix - KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'.format(gnb.score(x_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'.format(gnb.score(x_test, y_test)))\n",
    "\n",
    "test_pred_gnb = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, test_pred_gnb)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(matrix_df, annot=True, fmt='g', ax=ax, cmap='magma')\n",
    "\n",
    "ax.set_title('Confusion Matrix - KNN')\n",
    "ax.set_xlabel('Predicted label', fontsize=15)\n",
    "ax.set_xticklabels(['M', 'F'], fontsize=15)\n",
    "ax.set_ylabel('True Label', fontsize=15)\n",
    "ax.set_yticklabels(['M', 'F'], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'.format(svm.score(x_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(x_test, y_test)))\n",
    "\n",
    "test_pred_svm = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, test_pred_svm)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(matrix_df, annot=True, fmt='g', ax=ax, cmap='magma')\n",
    "\n",
    "ax.set_title('Confusion Matrix - SVC')\n",
    "ax.set_xlabel('Predicted label', fontsize=15)\n",
    "ax.set_xticklabels(['M', 'F'], fontsize=15)\n",
    "ax.set_ylabel('True Label', fontsize=15)\n",
    "ax.set_yticklabels(['M', 'F'], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneR(object):\n",
    "  def __init__(self):\n",
    "    self.ideal_variable = None\n",
    "    self.max_accuracy = 0\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    response = list()\n",
    "    result = dict()\n",
    "\n",
    "    dfx = pd.DataFrame(X)\n",
    "\n",
    "    for i in dfx:\n",
    "      result[str(i)] = dict()\n",
    "      options_values = set(dfx[i])\n",
    "      join_data = pd.DataFrame({'variable': dfx[i], 'label': y})\n",
    "      cross_table = pd.crosstab(join_data.variable, join_data.label)\n",
    "      summary = cross_table.idxmax(axis=1)\n",
    "      result[str(i)] = dict(summary)\n",
    "\n",
    "      counts = 0\n",
    "\n",
    "      for idx, row in join_data.iterrows():\n",
    "        if row['label'] == result[str(i)][row['variable']]:\n",
    "          counts += 1\n",
    "\n",
    "      accuracy = (counts/len(y))\n",
    "\n",
    "      if accuracy > self.max_accuracy:\n",
    "        self.max_accuracy = accuracy\n",
    "        self.ideal_variable = i\n",
    "\n",
    "      result_feature = {'variable': str(i), 'accuracy': accuracy, 'rules': result[str(i)]}\n",
    "      response.append(result_feature)\n",
    "\n",
    "    return response\n",
    "\n",
    "  def predict(self, X=None):\n",
    "    self_ideal_variable = self.ideal_variable + 1\n",
    "\n",
    "  def __repr__(self):\n",
    "    if self.ideal_variable != None:\n",
    "      txt = 'The best variable for this data is ' + str(self.ideal_variable)\n",
    "    else:\n",
    "      txt = 'The best variable has not been found yet, try running the fit method first'\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneR()\n",
    "test_results = clf.fit(x_test, y_test)\n",
    "\n",
    "print(test_results)\n",
    "print(clf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a3918ab7912738fba8fe58f000699587e8688dc2ccda4e63ff7b275fcbe4377"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
