{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read csv file into a pandas dataframe\n",
    "df = pd.read_csv('BlackFriday.csv', header=None)\n",
    "df.columns = ['User_ID', 'Lat', 'Long', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase']\n",
    "df.drop(index=df.index[0], axis=0, inplace=True) # Remove first row of data\n",
    "\n",
    "# Create a copy of our data frame to work with\n",
    "data = df.copy()\n",
    "\n",
    "# Print summary statistics\n",
    "print('The dataset has {} rows and {} columns'.format(data.shape[0], data.shape[1]))\n",
    "print(data.describe())\n",
    "print(data.head())\n",
    "print(data.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Lat'] = pd.to_numeric(data['Lat'], errors='coerce') # Convert Lat attribute to numeric\n",
    "data['Long'] = pd.to_numeric(data['Long'], errors='coerce') # Convert Long attribute to numeric\n",
    "data['Purchase'] = pd.to_numeric(data['Purchase'], errors='coerce') # Convert Purchase attribute to numeric\n",
    "\n",
    "print(data.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76cb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_attributes = data.columns[data.dtypes != \"object\"]\n",
    "categorical_attributes = data.columns[data.dtypes == \"object\"]\n",
    "\n",
    "print(numeric_attributes)\n",
    "print(categorical_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of missing values\n",
    "print(\"There are {} missing values in this dataset\".format(data.isnull().sum().sum()))\n",
    "\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in data.columns:\n",
    "    print('\\t%s: %d' % (col, data[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows which contain any NaN values. Note we are making a copy of the dataframe here\n",
    "modified_data = data.dropna()\n",
    "\n",
    "# Print the total number of missing values\n",
    "print(\"There are {} missing values in this dataset\".format(modified_data.isnull().sum().sum()))\n",
    "\n",
    "print('Number of instances = %d' % (modified_data.shape[0]))\n",
    "print('Number of attributes = %d' % (modified_data.shape[1]))\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in modified_data.columns:\n",
    "    print('\\t%s: %d' % (col, modified_data[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data['Product_Category_2']\n",
    "data3 = data['Product_Category_3']\n",
    "\n",
    "print('Before replacing missing values:')\n",
    "print(data2[20:25])\n",
    "print(data3[20:25])\n",
    "data2 = data2.fillna(data2.median())\n",
    "data3 = data3.fillna(data3.median())\n",
    "\n",
    "print('\\nAfter replacing missing values:')\n",
    "print(data2[20:25])\n",
    "print(data3[20:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all missing values with user defined constant\n",
    "print('Before replacing missing values:')\n",
    "print(data[20:25])\n",
    "\n",
    "data4 = data.copy()\n",
    "\n",
    "data4 = data4.replace(np.NaN , \"?\")\n",
    "\n",
    "print('\\nAfter replacing missing values:')\n",
    "print(data4[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data.copy()\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in data5.columns:\n",
    "    print('\\t%s: %d' % (col,data5[col].isna().sum()))\n",
    "\n",
    "data5.drop('Product_Category_2', axis=1, inplace=True) # axis=0 for rows, axis=1 for columns\n",
    "data5.drop('Product_Category_3', axis=1, inplace=True) # axis=0 for rows, axis=1 for columns\n",
    "\n",
    "print('Number of missing values after removal:')\n",
    "for col in data5.columns:\n",
    "    print('\\t%s: %d' % (col, data5[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff08a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data['Purchase'].hist(bins=10)\n",
    "data['Purchase'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.cut(data['Purchase'], 4)\n",
    "bins.value_counts(sort=False)\n",
    "\n",
    "data6 = data.groupby(bins)\n",
    "data6['Purchase'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.qcut(data['Purchase'], 4)\n",
    "bins.value_counts(sort=False)\n",
    "\n",
    "data7 = data.groupby(bins)\n",
    "data7['Purchase'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e87ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data8 = data[['User_ID', 'Lat', 'Long', 'Purchase']]\n",
    "print(data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.01, random_state=1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.01, replace=True, random_state=1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer() # Load dataset from sklearn library\n",
    "\n",
    "df = pd.DataFrame(dataset['data'], columns=dataset['feature_names'])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaled_data = scaler.transform(df)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2) # Reduce the dimensions from 30 to 2 dimensions\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_pca[:,0], x_pca[:,1], c=dataset['target'])\n",
    "plt.xlabel('First principle component')\n",
    "plt.ylabel('Second principle component')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data9 = data[['Marital_Status', 'Purchase']]\n",
    "data9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d225ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Create an abs_scaler object\n",
    "abs_scaler = MaxAbsScaler()\n",
    "\n",
    "# Calculate the maximum absolute value for scaling the data using the fit method\n",
    "abs_scaler.fit(data9)\n",
    "\n",
    "# The maximum absolute values calculated by the fit method\n",
    "abs_scaler.max_abs_\n",
    "# array([4.0e+05, 1.7e+01])\n",
    "\n",
    "# Transform the data using the parameters calculated by the fit method (the maximum absolute values)\n",
    "scaled_data = abs_scaler.transform(data9)\n",
    "\n",
    "# Store the results in a data frame\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=data9.columns)\n",
    "\n",
    "# Visualize the data frame\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "df_norm = pd.DataFrame(scaler.fit_transform(data9), columns=data9.columns)\n",
    "\n",
    "print(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ad68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a scaler object\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler\n",
    "\n",
    "# fit and transform the data\n",
    "df_std = pd.DataFrame(std_scaler.fit_transform(data9), columns=data9.columns)\n",
    "\n",
    "print(df_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
